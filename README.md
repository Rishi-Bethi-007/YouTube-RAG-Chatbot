# ğŸ¥ YouTube RAG Chatbot  
### Production-Grade Retrieval-Augmented Generation System with Memory

ğŸš€ **Live Demo:**  
ğŸ‘‰ https://youtube-multi-video-playlist-rag-be5fqxqp9w7rvcffmlp3dk.streamlit.app/

---

## ğŸ”¥ Overview

This project is a **production-style Retrieval-Augmented Generation (RAG) system** that allows users to chat with multiple YouTube videos or entire playlists using a conversational interface.

Unlike demo RAG apps, this system is built with:

- Scalable vector search
- Persistent relational storage
- Distributed caching
- Query rewriting
- Reranking
- Deduplication
- Evaluation harness
- Latency tracking
- Memory-aware chatbot behavior
- Cloud deployment

It demonstrates real-world AI system design beyond notebooks and toy examples.

---

# ğŸ§  What Problem Does This Solve?

YouTube videos are long and difficult to search precisely.

This system enables users to:

- Ingest multiple videos or playlists
- Ask natural language questions
- Get timestamped citations
- Continue conversations with memory
- Reduce hallucinations via grounding
- Measure retrieval quality
- Deploy publicly

---
# ğŸ—ï¸ System Architecture
````

User (Streamlit Chat UI)
â†“
Conversation Summary Memory
â†“
Query Rewriting (context-aware)
â†“
Embedding (cached)
â†“
Pinecone Vector Search
â†“
PostgreSQL (source-of-truth chunks)
â†“
LLM Reranking
â†“
Answer Generation (grounded + citations)

````

---

# ğŸ—‚ï¸ Storage Design

| Component      | Responsibility |
|---------------|---------------|
| **Pinecone**  | Stores embeddings + minimal metadata |
| **PostgreSQL**| Stores full chunk text + video metadata |
| **Redis**     | Caches rewrite / embeddings / retrieval |
| **Streamlit** | UI + session memory |



# âœ¨ Key Features

## âœ… Multi-Video & Playlist Ingestion
- Automatic chunking with overlap
- Timestamp-aware metadata
- Idempotent ingestion (dedup safe)
- SHA1-based chunk identity
- Safe re-indexing

## âœ… Conversation Memory
- Rolling summary (token-efficient)
- Multi-turn contextual dialogue
- Follow-up resolution:
  - â€œWhat about that part?â€
  - â€œExplain that in more detailâ€

## âœ… Production Caching (Redis)
- Query rewrite cache
- Embedding cache
- Retrieval cache
- Chunk text cache
- Fail-open design (app runs even if cache fails)

## âœ… Reranking Layer
Improves precision by re-evaluating top-K candidates before final generation.

## âœ… Deduplication
- Stable chunk IDs
- DB constraints
- Safe re-ingestion

## âœ… Evaluation Harness
- RAGAS metrics
- Faithfulness scoring
- Retrieval quality measurement
- Latency logging per stage

## âœ… Observability
Per-stage latency tracking:
- Rewrite
- Embedding
- Retrieval
- DB fetch
- Rerank
- Generation



# ğŸ“Š Why This Is Not a Demo RAG

Most RAG projects:
- Store full text in vector DB
- No deduplication
- No caching
- No memory
- No evaluation
- No deployment

This project demonstrates:

- Proper separation of vector store vs source-of-truth database
- Scalable architecture
- Cloud-ready design
- Caching strategy
- Evaluation mindset
- Token-efficient memory handling
- Production resilience

---

# ğŸ› ï¸ Tech Stack

- **Python**
- **Streamlit**
- **OpenAI API**
- **Pinecone**
- **PostgreSQL (Neon)**
- **Redis (Upstash)**
- **LangChain**
- **RAGAS**
- **Docker (local dev)**


# ğŸ“‚ Project Structure

````
youtube-multi-video-playlist-rag/
â”œâ”€ app.py
â”œâ”€ requirements.txt
â”œâ”€ docker-compose.yml
â”œâ”€ README.md
â””â”€ src/
  â”œâ”€ config.py
  â”œâ”€ cache.py
  â”œâ”€ db.py
  â”œâ”€ models.py
  â”œâ”€ ingest.py
  â”œâ”€ retrieve.py
  â”œâ”€ rewrite.py
  â”œâ”€ rerank.py
  â”œâ”€ memory.py
â””â”€ eval/
````

# ğŸŒ Deployment

Deployed on:

- **Streamlit Community Cloud**
- **Neon (Postgres)**
- **Upstash (Redis)**
- **Pinecone (Vector DB)**

The system runs fully in the cloud using managed services.


# ğŸ” Example Use Cases

- â€œWhat are the main themes discussed?â€
- â€œExplain the concept mentioned at the beginning.â€
- â€œWhat does the speaker say about embeddings?â€
- â€œCompare what two videos say about scalability.â€
- â€œSummarize the key takeaways.â€


# ğŸ“ˆ Future Improvements

- Hybrid retrieval (BM25 + vector)
- MMR pre-reranking
- Persistent chat sessions
- User authentication
- Cost logging dashboard
- Structured JSON outputs


# ğŸ‘¨â€ğŸ’» About the Author

**Rishi Bethi**  
MSc AI & Automation  
AI Engineer focused on production-grade LLM systems


# â­ Why This Project Matters

This project demonstrates:

- AI system architecture
- Retrieval engineering
- Production design thinking
- Data modeling
- Caching strategies
- Evaluation-first mindset
- Deployment capability

It reflects real-world AI engineering practices rather than experimental notebooks.

